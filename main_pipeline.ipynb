{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45be7114-ba11-495c-861b-61076e8534c5",
   "metadata": {},
   "source": [
    "<h3>Imports & Paths</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f28a638-9932-4ce3-9b32-7ce698dd674e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/dulaldas5/Group_43_RAG_vs_FT/data/raw/infosys-ar-25.pdf'),\n",
       " PosixPath('/Users/dulaldas5/Group_43_RAG_vs_FT/data/raw/annual-report-2024.pdf')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "\n",
    "# Project paths\n",
    "ROOT = Path(\"/Users/dulaldas5/Group_43_RAG_vs_FT\")\n",
    "RAW_DIR   = ROOT / \"data\" / \"raw\"\n",
    "CLEAN_DIR = ROOT / \"data\" / \"cleaned_text\"\n",
    "PROC_DIR  = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "CLEAN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "list(RAW_DIR.glob(\"*.pdf\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799fee99-bd08-42cd-ab25-cf153e1bb814",
   "metadata": {},
   "source": [
    "<h3>Utility Helpers</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34067f24-a52d-4717-a337-a7c35b6aaeda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "419d2fa0-c170-4914-bb5f-4cfc7173b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADER_FOOTER_HINTS = [\n",
    "    r\"^page\\s*\\d+(\\s*of\\s*\\d+)?$\",   # Page 1 of 100\n",
    "    r\"^\\d+$\",                        # just a number (often a page number)\n",
    "]\n",
    "\n",
    "def clean_lines(lines: List[str]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Basic line-level cleanup:\n",
    "    - strip\n",
    "    - drop obvious headers/footers/page numbers\n",
    "    - drop very short all-caps tokens\n",
    "    - collapse multiple spaces\n",
    "    \"\"\"\n",
    "    cleaned = []\n",
    "    for ln in lines:\n",
    "        s = ln.strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        drop = False\n",
    "        for pat in HEADER_FOOTER_HINTS:\n",
    "            if re.fullmatch(pat, s, flags=re.IGNORECASE):\n",
    "                drop = True\n",
    "                break\n",
    "        if drop:\n",
    "            continue\n",
    "        if len(s) <= 3 and s.isupper():\n",
    "            continue\n",
    "        s = re.sub(r\"\\s+\", \" \", s)\n",
    "        cleaned.append(s)\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecb8e3f-bdaf-46e4-91e7-ee19edb212c2",
   "metadata": {},
   "source": [
    "<h3>Metric Patterns & Extraction</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98098796-3aea-4e78-8973-dbeb1cc8b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pdf_text(pdf_path: Path) -> Tuple[str, List[Tuple[int, str]]]:\n",
    "    \"\"\"\n",
    "    Extract text per page using PyMuPDF and clean it.\n",
    "    Returns: (full_clean_text, [(page_no, page_clean_text), ...])\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    pages = []\n",
    "    for pno in range(len(doc)):\n",
    "        page = doc[pno]\n",
    "        raw = page.get_text(\"text\") or \"\"\n",
    "        clines = clean_lines(raw.splitlines())\n",
    "        pages.append((pno + 1, \"\\n\".join(clines)))\n",
    "    doc.close()\n",
    "\n",
    "    full = \"\\n\\n\".join(t for _, t in pages if t.strip())\n",
    "    return full, pages\n",
    "\n",
    "def write_clean_text(doc_name: str, full_text: str, pages: List[Tuple[int, str]]):\n",
    "    (CLEAN_DIR / f\"{doc_name}.txt\").write_text(full_text, encoding=\"utf-8\")\n",
    "    per_page = [{\"page\": p, \"text\": t} for p, t in pages]\n",
    "    (CLEAN_DIR / f\"{doc_name}.pages.json\").write_text(\n",
    "        json.dumps(per_page, ensure_ascii=False, indent=2), encoding=\"utf-8\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab497127-fd28-4187-a026-76640702a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SECTION_PATTERNS = {\n",
    "    \"balance_sheet\": r\"\\b(balance\\s+sheet|statement\\s+of\\s+financial\\s+position)\\b\",\n",
    "    \"income_statement\": r\"\\b(income\\s+statement|profit\\s+and\\s+loss|statement\\s+of\\s+operations)\\b\",\n",
    "    \"cash_flow\": r\"\\b(cash\\s+flow|statement\\s+of\\s+cash\\s+flows)\\b\",\n",
    "    \"mdna\": r\"\\b(management\\s+discussion\\s+and\\s+analysis|md&a)\\b\",\n",
    "    \"notes\": r\"\\b(notes\\s+to\\s+the\\s+financial\\s+statements|notes\\s+to\\s+accounts)\\b\",\n",
    "}\n",
    "\n",
    "def rough_section_indices(text: str) -> Dict[str, List[int]]:\n",
    "    idx = {}\n",
    "    low = text.lower()\n",
    "    for name, pat in SECTION_PATTERNS.items():\n",
    "        idx[name] = [m.start() for m in re.finditer(pat, low)]\n",
    "    return idx\n",
    "\n",
    "def segment_sections(text: str) -> Dict[str, str]:\n",
    "    indices = rough_section_indices(text)\n",
    "    all_starts = []\n",
    "    for sec, starts in indices.items():\n",
    "        for s in starts:\n",
    "            all_starts.append((s, sec))\n",
    "    if not all_starts:\n",
    "        return {\"full_report\": text}\n",
    "\n",
    "    all_starts.sort(key=lambda x: x[0])\n",
    "    result = {}\n",
    "    for i, (start, sec) in enumerate(all_starts):\n",
    "        end = all_starts[i+1][0] if i+1 < len(all_starts) else len(text)\n",
    "        if sec not in result:  # keep first occurrence only\n",
    "            result[sec] = text[start:end].strip()\n",
    "    if not result:\n",
    "        result[\"full_report\"] = text\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d8072e-dbeb-4664-b450-378505a13356",
   "metadata": {},
   "source": [
    "<h3>Chunking (100-word & 400-word windows with overlap)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6715f529-41fb-4742-8c4e-dfaafe506b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_words(words, chunk_size, overlap=20):\n",
    "    i = 0\n",
    "    n = len(words)\n",
    "    while i < n:\n",
    "        j = min(i + chunk_size, n)\n",
    "        yield (i, j, \" \".join(words[i:j]))\n",
    "        if j == n:\n",
    "            break\n",
    "        i = max(j - overlap, i + 1)\n",
    "\n",
    "def make_chunks(doc_name: str, full_text: str, pages: List[Tuple[int, str]], sizes=(100, 400)):\n",
    "    # Map approx page spans for traceability\n",
    "    page_word_spans = []\n",
    "    cum = 0\n",
    "    for p, t in pages:\n",
    "        wc = len(t.split())\n",
    "        page_word_spans.append((p, cum, cum + wc))\n",
    "        cum += wc\n",
    "\n",
    "    def span_to_pages(start_w: int, end_w: int):\n",
    "        touched = []\n",
    "        for p, a, b in page_word_spans:\n",
    "            if end_w <= a:\n",
    "                break\n",
    "            if start_w >= b:\n",
    "                continue\n",
    "            touched.append(p)\n",
    "        if not touched:\n",
    "            return []\n",
    "        return [min(touched), max(touched)] if len(touched) > 1 else [touched[0], touched[0]]\n",
    "\n",
    "    words = full_text.split()\n",
    "    outputs = {}\n",
    "    for sz in sizes:\n",
    "        chunks = []\n",
    "        for idx, (start, end, text) in enumerate(chunk_words(words, chunk_size=sz, overlap=20)):\n",
    "            chunks.append({\n",
    "                \"chunk_id\": f\"{doc_name}_{sz}_{idx:05d}\",\n",
    "                \"doc_name\": doc_name,\n",
    "                \"chunk_size_words\": sz,\n",
    "                \"start_word_index\": start,\n",
    "                \"end_word_index\": end,\n",
    "                \"pages_approx\": span_to_pages(start, end),\n",
    "                \"text\": text\n",
    "            })\n",
    "        outputs[sz] = chunks\n",
    "    return outputs\n",
    "\n",
    "def save_chunks(all_chunks: Dict[int, list]):\n",
    "    PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    for sz, chs in all_chunks.items():\n",
    "        # JSONL\n",
    "        jsonl_path = PROC_DIR / f\"chunks_{sz}.jsonl\"\n",
    "        with open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for c in chs:\n",
    "                f.write(json.dumps(c, ensure_ascii=False) + \"\\n\")\n",
    "        # JSON (convenience)\n",
    "        (PROC_DIR / f\"chunks_{sz}.json\").write_text(\n",
    "            json.dumps(chs, ensure_ascii=False, indent=2), encoding=\"utf-8\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f15adf2-6577-48c1-a566-c560bb0d03b3",
   "metadata": {},
   "source": [
    "<h3>Run on All Raw PDFs</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63aed31a-23a1-4c71-b687-99385864e160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing annual-report-2024.pdf ...\n",
      "[INFO] Processing infosys-ar-25.pdf ...\n",
      "\n",
      "[STATS] Documents processed: ['annual-report-2024.pdf', 'infosys-ar-25.pdf']\n",
      "[STATS] 100-word chunks: 4212\n",
      "[STATS] 400-word chunks: 888\n",
      "[OK] Outputs saved to: /Users/dulaldas5/Group_43_RAG_vs_FT/data/processed\n"
     ]
    }
   ],
   "source": [
    "pdfs = sorted(RAW_DIR.glob(\"*.pdf\"))\n",
    "assert len(pdfs) > 0, \"No PDFs found in data/raw/. Please add your annual reports.\"\n",
    "\n",
    "all_chunks_100, all_chunks_400 = [], []\n",
    "\n",
    "for pdf in pdfs:\n",
    "    doc_name = pdf.stem\n",
    "    print(f\"[INFO] Processing {pdf.name} ...\")\n",
    "    full_text, pages = extract_pdf_text(pdf)\n",
    "    # Save cleaned text + per-page JSON\n",
    "    write_clean_text(doc_name, full_text, pages)\n",
    "    # Save rough section splits for reference\n",
    "    sections = segment_sections(full_text)\n",
    "    (CLEAN_DIR / f\"{doc_name}.sections.json\").write_text(\n",
    "        json.dumps(sections, ensure_ascii=False, indent=2), encoding=\"utf-8\"\n",
    "    )\n",
    "    # Build chunks (100 & 400)\n",
    "    chunks_by_size = make_chunks(doc_name, full_text, pages, sizes=(100, 400))\n",
    "    all_chunks_100.extend(chunks_by_size[100])\n",
    "    all_chunks_400.extend(chunks_by_size[400])\n",
    "\n",
    "# Save combined chunk files\n",
    "save_chunks({100: all_chunks_100, 400: all_chunks_400})\n",
    "\n",
    "print(\"\\n[STATS] Documents processed:\", [p.name for p in pdfs])\n",
    "print(\"[STATS] 100-word chunks:\", len(all_chunks_100))\n",
    "print(\"[STATS] 400-word chunks:\", len(all_chunks_400))\n",
    "print(\"[OK] Outputs saved to:\", PROC_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957a2e80-f21c-47d1-a599-a8dd7beb0b48",
   "metadata": {},
   "source": [
    "<h3>Quick Peek / Sanity Check</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6dc1e1c-4c2b-4de3-a6e5-2a8b58acfd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned text files: ['annual-report-2024.txt', 'infosys-ar-25.txt']\n",
      "\n",
      "Sample cleaned lines:\n",
      " Generative AI and You\n",
      "Integrated Annual Report 2023-24\n",
      "\n",
      "Infosys Integrated Annual Report 2023-24\n",
      "We barely saw it happen. AI walking into our lives. Through\n",
      "the ads that follow us on social media. The personalized\n",
      "pick of movies and shows. Our cars. The maps helping us\n",
      "navigate. Right there in our hands – our super-powerful\n",
      "phones. And now, it’s happening again. This time with\n",
      "generative AI. In the form of handy tools – like ChatGPT,\n",
      "MetaAI and Stable Diffusion – that pique our imagination,\n",
      "and stoke our curiosity.\n",
      "Generative AI technology’s path into enterprises too has\n",
      "been just as accelerated and enthusiastic, supported by\n",
      "an exponential increase in investments. While almost\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>pages_approx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>annual-report-2024_100_00000</td>\n",
       "      <td>[1, 2]</td>\n",
       "      <td>Generative AI and You Integrated Annual Report...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>annual-report-2024_100_00001</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>pique our imagination, and stoke our curiosity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>annual-report-2024_100_00002</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>believe, some ongoing AI pilots will scale to ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       chunk_id pages_approx  \\\n",
       "0  annual-report-2024_100_00000       [1, 2]   \n",
       "1  annual-report-2024_100_00001       [2, 2]   \n",
       "2  annual-report-2024_100_00002       [2, 2]   \n",
       "\n",
       "                                                text  \n",
       "0  Generative AI and You Integrated Annual Report...  \n",
       "1  pique our imagination, and stoke our curiosity...  \n",
       "2  believe, some ongoing AI pilots will scale to ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show a few cleaned lines and a couple of chunks for verification\n",
    "txt_files = sorted(CLEAN_DIR.glob(\"*.txt\"))\n",
    "print(\"Cleaned text files:\", [p.name for p in txt_files][:5])\n",
    "\n",
    "sample_txt = txt_files[0].read_text(encoding=\"utf-8\").splitlines()[:15]\n",
    "print(\"\\nSample cleaned lines:\\n\", \"\\n\".join(sample_txt))\n",
    "\n",
    "import json\n",
    "sample_100 = json.loads((PROC_DIR / \"chunks_100.json\").read_text(encoding=\"utf-8\"))[:3]\n",
    "pd.DataFrame(sample_100)[[\"chunk_id\",\"pages_approx\",\"text\"]].head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6609e30e-d38d-492c-87c4-76563221bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_QA_JSONL = ROOT / \"data\" / \"qa_pairs.jsonl\"\n",
    "OUT_QA_CSV   = ROOT / \"data\" / \"qa_pairs.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b6ac402-f680-4587-bb1f-967f3c1f8464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_texts(clean_dir: Path) -> Dict[str, str]:\n",
    "    texts = {}\n",
    "    for p in clean_dir.glob(\"*.txt\"):\n",
    "        texts[p.stem] = p.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    return texts\n",
    "\n",
    "def load_sections(clean_dir: Path) -> Dict[str, Dict[str, str]]:\n",
    "    sections = {}\n",
    "    for p in clean_dir.glob(\"*.sections.json\"):\n",
    "        try:\n",
    "            sections[p.stem.replace(\".sections\",\"\")] = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return sections\n",
    "\n",
    "def normalize_spaces(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "def guess_company_from_text(doc_name: str, text: str) -> str:\n",
    "    first = \"\\n\".join(text.splitlines()[:20])\n",
    "    m = re.search(r\"\\b([A-Z][a-zA-Z]+(?:\\s+[A-Z][a-zA-Z]+){0,3})\\b\", first)\n",
    "    return m.group(1) if m else doc_name\n",
    "\n",
    "def find_years(text: str):\n",
    "    return sorted({int(y) for y in re.findall(r\"\\b(20\\d{2})\\b\", text)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0e4509-675a-4f2d-9bde-1981f2c30456",
   "metadata": {},
   "source": [
    "<h3>Patterns & Extraction</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6ee8a52-c653-4948-a2f7-1faa5a58be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount/units patterns\n",
    "CURRENCY = r\"(?:₹|\\$|USD|EUR|INR|Rs\\.?)?\"\n",
    "NUM      = r\"(?:\\d{1,3}(?:[,\\s]\\d{3})*(?:\\.\\d+)?|\\d+(?:\\.\\d+)?)\"\n",
    "UNITS    = r\"(?:\\s?(?:million|billion|mn|bn|crore|lakh|cr|m|bn))?\"\n",
    "AMOUNT   = CURRENCY + r\"\\s*\" + NUM + r\"\\s*\" + UNITS\n",
    "\n",
    "METRIC_PATTERNS = {\n",
    "    \"revenue\":      r\"\\b(revenue|total\\s+revenue|net\\s+sales|sales)\\b[:\\s\\-–]*\" + AMOUNT,\n",
    "    \"net_income\":   r\"\\b(net\\s+(?:income|profit)|profit\\s+after\\s+tax|PAT)\\b[:\\s\\-–]*\" + AMOUNT,\n",
    "    \"ebitda\":       r\"\\b(EBITDA)\\b[:\\s\\-–]*\" + AMOUNT,\n",
    "    \"eps\":          r\"\\b(EPS|earnings\\s+per\\s+share)\\b[:\\s\\-–]*\" + AMOUNT,\n",
    "    \"cash_flow\":    r\"\\b(net\\s+cash\\s+from\\s+operating\\s+activities|operating\\s+cash\\s+flow)\\b[:\\s\\-–]*\" + AMOUNT,\n",
    "    \"assets\":       r\"\\b(total\\s+assets)\\b[:\\s\\-–]*\" + AMOUNT,\n",
    "    \"liabilities\":  r\"\\b(total\\s+liabilities)\\b[:\\s\\-–]*\" + AMOUNT,\n",
    "}\n",
    "\n",
    "def clean_amount(val: str) -> str:\n",
    "    v = normalize_spaces(val)\n",
    "    v = v.replace(\"USD\", \"USD \").replace(\"INR\", \"INR \").replace(\"Rs.\", \"Rs \")\n",
    "    v = re.sub(r\"\\s+\", \" \", v)\n",
    "    return v.strip()\n",
    "\n",
    "def extract_metric_sentences(text: str, metric: str, pattern: str) -> List[Dict[str, Any]]:\n",
    "    out = []\n",
    "    for m in re.finditer(pattern, text, flags=re.IGNORECASE):\n",
    "        span = m.span()\n",
    "        start = max(0, span[0] - 160)\n",
    "        end   = min(len(text), span[1] + 160)\n",
    "        context = normalize_spaces(text[start:end])\n",
    "        raw = normalize_spaces(m.group(0))\n",
    "        amt_m = re.search(AMOUNT, raw, flags=re.IGNORECASE)\n",
    "        amount = clean_amount(amt_m.group(0)) if amt_m else raw\n",
    "        near = text[max(0, span[0]-80): min(len(text), span[1]+80)]\n",
    "        year_m = re.search(r\"\\b(20\\d{2})\\b\", near)\n",
    "        year = int(year_m.group(1)) if year_m else None\n",
    "        out.append({\"metric\": metric, \"amount\": amount, \"year\": year, \"raw\": raw, \"context\": context})\n",
    "    return out\n",
    "\n",
    "def extract_all_metrics(text: str) -> List[Dict[str, Any]]:\n",
    "    results = []\n",
    "    for metric, pat in METRIC_PATTERNS.items():\n",
    "        results.extend(extract_metric_sentences(text, metric, pat))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528c07c8-10e3-458f-9f5e-3719ce875a6f",
   "metadata": {},
   "source": [
    "<h3>Build Q/A Candidates</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ac7d997-aec5-4bc5-af4e-9e3d8dd0f3f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = load_clean_texts(CLEAN_DIR)\n",
    "sections = load_sections(CLEAN_DIR)\n",
    "\n",
    "candidates = []\n",
    "for doc_name, txt in texts.items():\n",
    "    company = guess_company_from_text(doc_name, txt)\n",
    "    facts = extract_all_metrics(txt)\n",
    "\n",
    "    for f in facts:\n",
    "        metric, amount, year, ctx = f[\"metric\"], f[\"amount\"], f[\"year\"], f[\"context\"]\n",
    "\n",
    "        if metric == \"revenue\":\n",
    "            q = f\"What was {company}'s revenue in {year}?\"\n",
    "        elif metric == \"net_income\":\n",
    "            q = f\"What was {company}'s net income in {year}?\"\n",
    "        elif metric == \"ebitda\":\n",
    "            q = f\"What was {company}'s EBITDA in {year}?\"\n",
    "        elif metric == \"eps\":\n",
    "            q = f\"What was {company}'s EPS in {year}?\"\n",
    "        elif metric == \"cash_flow\":\n",
    "            q = f\"What was {company}'s operating cash flow in {year}?\"\n",
    "        elif metric == \"assets\":\n",
    "            q = f\"What were {company}'s total assets in {year}?\"\n",
    "        elif metric == \"liabilities\":\n",
    "            q = f\"What were {company}'s total liabilities in {year}?\"\n",
    "        else:\n",
    "            q = f\"What was {metric.replace('_',' ')} in {year} for {company}?\"\n",
    "\n",
    "        conf = 0.9 if (year is not None and re.search(NUM, amount)) else 0.6\n",
    "        candidates.append({\n",
    "            \"question\": q,\n",
    "            \"answer\": amount,\n",
    "            \"metric\": metric,\n",
    "            \"year\": year,\n",
    "            \"company\": company,\n",
    "            \"source_doc\": doc_name,\n",
    "            \"context_snippet\": ctx,\n",
    "            \"confidence_heuristic\": conf\n",
    "        })\n",
    "\n",
    "len(candidates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdcea1a-b174-44c8-afaf-6b4593b69e19",
   "metadata": {},
   "source": [
    "<h3>Deduplicate & Add YoY Comparison Q/As</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee1ee698-bc3e-468a-8ee9-1f257f1ef603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deduplicate by (question, answer)\n",
    "seen = set()\n",
    "uniq = []\n",
    "for it in candidates:\n",
    "    key = (it[\"question\"], it[\"answer\"])\n",
    "    if key not in seen:\n",
    "        seen.add(key)\n",
    "        uniq.append(it)\n",
    "\n",
    "def build_yoy_pairs(items: List[Dict[str, Any]], metric: str, company: str) -> List[Dict[str, Any]]:\n",
    "    by_year = {}\n",
    "    for it in items:\n",
    "        if it[\"metric\"] == metric and it[\"company\"] == company and it[\"year\"]:\n",
    "            by_year[it[\"year\"]] = it[\"answer\"]\n",
    "    years_sorted = sorted(by_year.keys(), reverse=True)\n",
    "    out = []\n",
    "    if len(years_sorted) >= 2:\n",
    "        y1, y2 = years_sorted[0], years_sorted[1]\n",
    "        q = f\"Compare {company}'s {metric.replace('_',' ')} in {y2} vs {y1}.\"\n",
    "        a = f\"{y2}: {by_year[y2]}; {y1}: {by_year[y1]}.\"\n",
    "        out.append({\n",
    "            \"question\": q,\n",
    "            \"answer\": a,\n",
    "            \"metric\": f\"{metric}_comparison\",\n",
    "            \"year\": f\"{y2} vs {y1}\",\n",
    "            \"company\": company,\n",
    "            \"source_doc\": \"multiple\",\n",
    "            \"context_snippet\": \"\",\n",
    "            \"confidence_heuristic\": 0.75\n",
    "        })\n",
    "    return out\n",
    "\n",
    "companies = sorted({it[\"company\"] for it in uniq})\n",
    "yoy = []\n",
    "for comp in companies:\n",
    "    yoy += build_yoy_pairs(uniq, \"revenue\", comp)\n",
    "    yoy += build_yoy_pairs(uniq, \"net_income\", comp)\n",
    "\n",
    "qa_dataset = uniq + yoy\n",
    "len(qa_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800e5148-9933-4cbb-9ce0-fd3f75109f61",
   "metadata": {},
   "source": [
    "<h3>Balance to ~50 Q/As</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d387f35f-2903-4218-906b-c633a720fd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total candidates: 21\n",
      "Balanced sample: 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>metric</th>\n",
       "      <th>year</th>\n",
       "      <th>company</th>\n",
       "      <th>source_doc</th>\n",
       "      <th>confidence_heuristic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was Integrated Annual Report's revenue in...</td>\n",
       "      <td>94,111</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What was Integrated Annual Report's revenue in...</td>\n",
       "      <td>1</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was Integrated Annual Report's revenue in...</td>\n",
       "      <td>6,713</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What was Integrated Annual Report's revenue in...</td>\n",
       "      <td>18.7</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was Integrated Annual Report's revenue in...</td>\n",
       "      <td>8,492</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What was Generative AI's revenue in None?</td>\n",
       "      <td>89,032</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Generative AI</td>\n",
       "      <td>annual-report-2024</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What was Generative AI's revenue in None?</td>\n",
       "      <td>1</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Generative AI</td>\n",
       "      <td>annual-report-2024</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What was Generative AI's revenue in None?</td>\n",
       "      <td>5,698</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Generative AI</td>\n",
       "      <td>annual-report-2024</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What was Integrated Annual Report's net income...</td>\n",
       "      <td>25,568</td>\n",
       "      <td>net_income</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What was Integrated Annual Report's net income...</td>\n",
       "      <td>26,750</td>\n",
       "      <td>net_income</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What was Generative AI's net income in None?</td>\n",
       "      <td>27,234</td>\n",
       "      <td>net_income</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Generative AI</td>\n",
       "      <td>annual-report-2024</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What was Generative AI's net income in None?</td>\n",
       "      <td>26,248</td>\n",
       "      <td>net_income</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Generative AI</td>\n",
       "      <td>annual-report-2024</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What were Integrated Annual Report's total ass...</td>\n",
       "      <td>1</td>\n",
       "      <td>assets</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What were Generative AI's total assets in 2023?</td>\n",
       "      <td>1</td>\n",
       "      <td>assets</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Generative AI</td>\n",
       "      <td>annual-report-2024</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What were Integrated Annual Report's total ass...</td>\n",
       "      <td>1</td>\n",
       "      <td>assets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  answer      metric  \\\n",
       "0   What was Integrated Annual Report's revenue in...  94,111     revenue   \n",
       "1   What was Integrated Annual Report's revenue in...       1     revenue   \n",
       "2   What was Integrated Annual Report's revenue in...   6,713     revenue   \n",
       "3   What was Integrated Annual Report's revenue in...    18.7     revenue   \n",
       "4   What was Integrated Annual Report's revenue in...   8,492     revenue   \n",
       "5           What was Generative AI's revenue in None?  89,032     revenue   \n",
       "6           What was Generative AI's revenue in None?       1     revenue   \n",
       "7           What was Generative AI's revenue in None?   5,698     revenue   \n",
       "8   What was Integrated Annual Report's net income...  25,568  net_income   \n",
       "9   What was Integrated Annual Report's net income...  26,750  net_income   \n",
       "10       What was Generative AI's net income in None?  27,234  net_income   \n",
       "11       What was Generative AI's net income in None?  26,248  net_income   \n",
       "12  What were Integrated Annual Report's total ass...       1      assets   \n",
       "13    What were Generative AI's total assets in 2023?       1      assets   \n",
       "14  What were Integrated Annual Report's total ass...       1      assets   \n",
       "\n",
       "      year                   company          source_doc  confidence_heuristic  \n",
       "0      NaN  Integrated Annual Report       infosys-ar-25                   0.6  \n",
       "1      NaN  Integrated Annual Report       infosys-ar-25                   0.6  \n",
       "2      NaN  Integrated Annual Report       infosys-ar-25                   0.6  \n",
       "3      NaN  Integrated Annual Report       infosys-ar-25                   0.6  \n",
       "4      NaN  Integrated Annual Report       infosys-ar-25                   0.6  \n",
       "5      NaN             Generative AI  annual-report-2024                   0.6  \n",
       "6      NaN             Generative AI  annual-report-2024                   0.6  \n",
       "7      NaN             Generative AI  annual-report-2024                   0.6  \n",
       "8      NaN  Integrated Annual Report       infosys-ar-25                   0.6  \n",
       "9      NaN  Integrated Annual Report       infosys-ar-25                   0.6  \n",
       "10     NaN             Generative AI  annual-report-2024                   0.6  \n",
       "11     NaN             Generative AI  annual-report-2024                   0.6  \n",
       "12  2024.0  Integrated Annual Report       infosys-ar-25                   0.9  \n",
       "13  2023.0             Generative AI  annual-report-2024                   0.9  \n",
       "14     NaN  Integrated Annual Report       infosys-ar-25                   0.6  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to cap to ~50 for FT while keeping variety\n",
    "def balanced_sample(items: List[Dict[str, Any]], per_metric: int = 8, max_total: int = 50):\n",
    "    by_metric = {}\n",
    "    for it in items:\n",
    "        by_metric.setdefault(it[\"metric\"], []).append(it)\n",
    "    sampled = []\n",
    "    # sort by confidence within each metric\n",
    "    for m, arr in by_metric.items():\n",
    "        arr_sorted = sorted(arr, key=lambda x: x.get(\"confidence_heuristic\", 0), reverse=True)\n",
    "        sampled.extend(arr_sorted[:per_metric])\n",
    "    # if more than max_total, keep highest-confidence globally\n",
    "    if len(sampled) > max_total:\n",
    "        sampled = sorted(sampled, key=lambda x: x.get(\"confidence_heuristic\", 0), reverse=True)[:max_total]\n",
    "    return sampled\n",
    "\n",
    "qa_balanced = balanced_sample(qa_dataset, per_metric=8, max_total=50)\n",
    "print(\"Total candidates:\", len(qa_dataset))\n",
    "print(\"Balanced sample:\", len(qa_balanced))\n",
    "df_preview = pd.DataFrame(qa_balanced)[[\"question\",\"answer\",\"metric\",\"year\",\"company\",\"source_doc\",\"confidence_heuristic\"]]\n",
    "df_preview.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4061b6f4-e4d9-46a2-9322-aa10b5aefb1c",
   "metadata": {},
   "source": [
    "<h3>Save Q/As (JSONL + CSV)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cdc2fd9-4909-490d-8aa7-af21d9f7cf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - /Users/dulaldas5/Group_43_RAG_vs_FT/data/qa_pairs.jsonl\n",
      " - /Users/dulaldas5/Group_43_RAG_vs_FT/data/qa_pairs.csv\n",
      "Total Q/A pairs saved: 21\n"
     ]
    }
   ],
   "source": [
    "to_save = qa_balanced if len(qa_balanced) >= 40 else qa_dataset  # fall back if not enough\n",
    "OUT_QA_JSONL.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(OUT_QA_JSONL, \"w\", encoding=\"utf-8\") as f:\n",
    "    for row in to_save:\n",
    "        f.write(json.dumps(row, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "pd.DataFrame(to_save).to_csv(OUT_QA_CSV, index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" -\", OUT_QA_JSONL.resolve())\n",
    "print(\" -\", OUT_QA_CSV.resolve())\n",
    "print(\"Total Q/A pairs saved:\", len(to_save))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05686206-9855-4463-a6a1-1d2736614512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>metric</th>\n",
       "      <th>year</th>\n",
       "      <th>company</th>\n",
       "      <th>source_doc</th>\n",
       "      <th>confidence_heuristic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What were Generative AI's total assets in 2023?</td>\n",
       "      <td>1</td>\n",
       "      <td>assets</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>Generative AI</td>\n",
       "      <td>annual-report-2024</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What were Integrated Annual Report's total ass...</td>\n",
       "      <td>1</td>\n",
       "      <td>assets</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What was Generative AI's revenue in None?</td>\n",
       "      <td>1</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Generative AI</td>\n",
       "      <td>annual-report-2024</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What were Generative AI's total assets in None?</td>\n",
       "      <td>26.6</td>\n",
       "      <td>assets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Generative AI</td>\n",
       "      <td>annual-report-2024</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What were Generative AI's total assets in None?</td>\n",
       "      <td>1</td>\n",
       "      <td>assets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Generative AI</td>\n",
       "      <td>annual-report-2024</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What was Generative AI's net income in None?</td>\n",
       "      <td>26,248</td>\n",
       "      <td>net_income</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Generative AI</td>\n",
       "      <td>annual-report-2024</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What was Generative AI's net income in None?</td>\n",
       "      <td>27,234</td>\n",
       "      <td>net_income</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Generative AI</td>\n",
       "      <td>annual-report-2024</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What was Generative AI's revenue in None?</td>\n",
       "      <td>107,413 102,353</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Generative AI</td>\n",
       "      <td>annual-report-2024</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What was Generative AI's revenue in None?</td>\n",
       "      <td>7,341</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Generative AI</td>\n",
       "      <td>annual-report-2024</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What was Generative AI's revenue in None?</td>\n",
       "      <td>21.1</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Generative AI</td>\n",
       "      <td>annual-report-2024</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What was Generative AI's revenue in None?</td>\n",
       "      <td>5,698</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Generative AI</td>\n",
       "      <td>annual-report-2024</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was Integrated Annual Report's revenue in...</td>\n",
       "      <td>94,111</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What was Integrated Annual Report's revenue in...</td>\n",
       "      <td>1</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What were Integrated Annual Report's total ass...</td>\n",
       "      <td>28.7</td>\n",
       "      <td>assets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What were Integrated Annual Report's total ass...</td>\n",
       "      <td>1</td>\n",
       "      <td>assets</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What was Integrated Annual Report's net income...</td>\n",
       "      <td>26,750</td>\n",
       "      <td>net_income</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What was Integrated Annual Report's net income...</td>\n",
       "      <td>25,568</td>\n",
       "      <td>net_income</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was Integrated Annual Report's revenue in...</td>\n",
       "      <td>8,492</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What was Integrated Annual Report's revenue in...</td>\n",
       "      <td>18.7</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What was Integrated Annual Report's revenue in...</td>\n",
       "      <td>6,713</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Annual Report</td>\n",
       "      <td>infosys-ar-25</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What was Generative AI's revenue in None?</td>\n",
       "      <td>89,032</td>\n",
       "      <td>revenue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Generative AI</td>\n",
       "      <td>annual-report-2024</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question           answer  \\\n",
       "20    What were Generative AI's total assets in 2023?                1   \n",
       "9   What were Integrated Annual Report's total ass...                1   \n",
       "11          What was Generative AI's revenue in None?                1   \n",
       "19    What were Generative AI's total assets in None?             26.6   \n",
       "18    What were Generative AI's total assets in None?                1   \n",
       "17       What was Generative AI's net income in None?           26,248   \n",
       "16       What was Generative AI's net income in None?           27,234   \n",
       "15          What was Generative AI's revenue in None?  107,413 102,353   \n",
       "14          What was Generative AI's revenue in None?            7,341   \n",
       "13          What was Generative AI's revenue in None?             21.1   \n",
       "12          What was Generative AI's revenue in None?            5,698   \n",
       "0   What was Integrated Annual Report's revenue in...           94,111   \n",
       "1   What was Integrated Annual Report's revenue in...                1   \n",
       "8   What were Integrated Annual Report's total ass...             28.7   \n",
       "7   What were Integrated Annual Report's total ass...                1   \n",
       "6   What was Integrated Annual Report's net income...           26,750   \n",
       "5   What was Integrated Annual Report's net income...           25,568   \n",
       "4   What was Integrated Annual Report's revenue in...            8,492   \n",
       "3   What was Integrated Annual Report's revenue in...             18.7   \n",
       "2   What was Integrated Annual Report's revenue in...            6,713   \n",
       "10          What was Generative AI's revenue in None?           89,032   \n",
       "\n",
       "        metric    year                   company          source_doc  \\\n",
       "20      assets  2023.0             Generative AI  annual-report-2024   \n",
       "9       assets  2024.0  Integrated Annual Report       infosys-ar-25   \n",
       "11     revenue     NaN             Generative AI  annual-report-2024   \n",
       "19      assets     NaN             Generative AI  annual-report-2024   \n",
       "18      assets     NaN             Generative AI  annual-report-2024   \n",
       "17  net_income     NaN             Generative AI  annual-report-2024   \n",
       "16  net_income     NaN             Generative AI  annual-report-2024   \n",
       "15     revenue     NaN             Generative AI  annual-report-2024   \n",
       "14     revenue     NaN             Generative AI  annual-report-2024   \n",
       "13     revenue     NaN             Generative AI  annual-report-2024   \n",
       "12     revenue     NaN             Generative AI  annual-report-2024   \n",
       "0      revenue     NaN  Integrated Annual Report       infosys-ar-25   \n",
       "1      revenue     NaN  Integrated Annual Report       infosys-ar-25   \n",
       "8       assets     NaN  Integrated Annual Report       infosys-ar-25   \n",
       "7       assets     NaN  Integrated Annual Report       infosys-ar-25   \n",
       "6   net_income     NaN  Integrated Annual Report       infosys-ar-25   \n",
       "5   net_income     NaN  Integrated Annual Report       infosys-ar-25   \n",
       "4      revenue     NaN  Integrated Annual Report       infosys-ar-25   \n",
       "3      revenue     NaN  Integrated Annual Report       infosys-ar-25   \n",
       "2      revenue     NaN  Integrated Annual Report       infosys-ar-25   \n",
       "10     revenue     NaN             Generative AI  annual-report-2024   \n",
       "\n",
       "    confidence_heuristic  \n",
       "20                   0.9  \n",
       "9                    0.9  \n",
       "11                   0.6  \n",
       "19                   0.6  \n",
       "18                   0.6  \n",
       "17                   0.6  \n",
       "16                   0.6  \n",
       "15                   0.6  \n",
       "14                   0.6  \n",
       "13                   0.6  \n",
       "12                   0.6  \n",
       "0                    0.6  \n",
       "1                    0.6  \n",
       "8                    0.6  \n",
       "7                    0.6  \n",
       "6                    0.6  \n",
       "5                    0.6  \n",
       "4                    0.6  \n",
       "3                    0.6  \n",
       "2                    0.6  \n",
       "10                   0.6  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(OUT_QA_CSV)\n",
    "display_cols = [\"question\",\"answer\",\"metric\",\"year\",\"company\",\"source_doc\",\"confidence_heuristic\"]\n",
    "df.sort_values(by=\"confidence_heuristic\", ascending=False)[display_cols].head(25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed5166a-95b9-49de-ab7e-e758168ad4b2",
   "metadata": {},
   "source": [
    "<h1>Step 2 (RAG)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "604a11e8-542f-4f48-bf22-e2d31aa8cc0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'faiss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer, CrossEncoder\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrank_bm25\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BM25Okapi\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfaiss\u001b[39;00m  \u001b[38;5;66;03m# CPU index\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Project paths (relative to repo root)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m ROOT \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/dulaldas5/Group_43_RAG_vs_FT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'faiss'"
     ]
    }
   ],
   "source": [
    "# If needed:\n",
    "# !pip install sentence-transformers faiss-cpu rank-bm25 scikit-learn pandas numpy tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "import faiss  # CPU index\n",
    "\n",
    "# Project paths (relative to repo root)\n",
    "ROOT = Path(\"/Users/dulaldas5/Group_43_RAG_vs_FT\")\n",
    "PROC_DIR   = ROOT / \"data\" / \"processed\"\n",
    "EMB_DIR    = ROOT / \"embeddings\"\n",
    "FAISS_DIR  = EMB_DIR / \"faiss_index\"\n",
    "BM25_DIR   = EMB_DIR / \"bm25_index\"\n",
    "\n",
    "for p in [EMB_DIR, FAISS_DIR, BM25_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Choose which chunk set to index (100 or 400-word chunks)\n",
    "CHUNK_SIZE_TO_USE = 400\n",
    "CHUNKS_PATH = PROC_DIR / f\"chunks_{CHUNK_SIZE_TO_USE}.jsonl\"\n",
    "\n",
    "assert CHUNKS_PATH.exists(), f\"Missing {CHUNKS_PATH}. Run Step 1 to generate chunk files.\"\n",
    "print(\"Using chunks file:\", CHUNKS_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a06c14fd-73b5-49be-a5ac-2ca5a3a006d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank-bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from rank-bm25) (2.2.1)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank-bm25\n",
      "Successfully installed rank-bm25-0.2.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Frameworks/Python.framework/Versions/3.13/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rank-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fa9b3cb-ab82-4d41-a05b-f58167f19f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Frameworks/Python.framework/Versions/3.13/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for faiss-gpu\u001b[0m\u001b[31m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a21757-fbeb-455e-b138-a5e007d3f9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
